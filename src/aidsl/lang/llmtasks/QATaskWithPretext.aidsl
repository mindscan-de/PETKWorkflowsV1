package aidsl.lang.llmtasks

vmnode super QATaskWithPretext {
	
	opcode "AITaskTemplate"
	
	fields {
		optional string short_task_header default ""
		optional string version default ""
		
		require string system_prompt default ""
		require string task_query
		require string task_context_template
		require string task_answer_pretext
		
		optional string[] extra_stopwords default []
	}
	
	
	in {
		// none
	}
	
	out {
		local.model_task as string
		result.llm.response.content as string
	}
}
